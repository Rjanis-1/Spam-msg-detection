# -*- coding: utf-8 -*-
"""Spam msg detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ziklQRCeLkXjR7GE5WhNgBcezVznvVWV
"""

from google.colab import files

uploaded = files.upload()  # This opens a file upload window

import os

print(os.listdir())  # This will list all files in your Colab session

import os

print(os.listdir())  # Lists all files in the current directory

from google.colab import files

# This will prompt you to select a file from your computer.
uploaded = files.upload()

import pandas as pd

df = pd.read_csv("SMSSpamCollection", sep="\t", header=None, names=["label", "message"])
print(df.head())

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer

# Download stopwords if needed
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
stemmer = SnowballStemmer("english")

def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove non-alphabet characters (keeping spaces)
    text = re.sub(r'[^a-z\s]', '', text)
    # Split into tokens and remove stopwords, apply stemming
    tokens = text.split()
    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]
    # Join tokens back to a string
    return " ".join(tokens)

# Apply preprocessing to each message
df["processed_message"] = df["message"].apply(preprocess_text)

# Check the results
print(df.head())

from sklearn.feature_extraction.text import TfidfVectorizer

# Limit the number of features to manage complexity
vectorizer = TfidfVectorizer(max_features=3000)
X = vectorizer.fit_transform(df["processed_message"]).toarray()

# Encode the labels: ham = 0, spam = 1
y = df["label"].map({"ham": 0, "spam": 1})

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

def predict_message(msg):
    # Preprocess the input message
    processed = preprocess_text(msg)

    # Convert the message to a TF-IDF vector
    msg_vector = vectorizer.transform([processed]).toarray()

    # Use the trained model to predict
    pred = model.predict(msg_vector)

    # Map numeric output back to label ("ham" for 0, "spam" for 1)
    return "spam" if pred[0] == 1 else "ham"

# Example usage:
sample_msg = "Congratulations! You've won a free ticket. Reply now to claim."
result = predict_message(sample_msg)
print("The message is:", result)

# Test with a legitimate message
print(predict_message("Hey, are we still meeting for lunch today?"))

# Test with a spam-like message
print(predict_message("Win $1000 now! Click here to claim your prize."))